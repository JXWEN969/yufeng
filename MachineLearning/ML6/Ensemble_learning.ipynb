{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的库\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.base import clone\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.定义一些常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR = pathlib.Path(\"D:/Amazon6\")  # 数据文件所在的目录\n",
    "SEED = 0  # 随机数种子\n",
    "NUM_ITER = 10  # 迭代次数\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 观察数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小：57039\n",
      "测试集大小：11208\n",
      "训练集前五行：\n",
      "   reviewerID   asin                                         reviewText  \\\n",
      "0        7885   3901  First off, allow me to correct a common mistak...   \n",
      "1       52087  47978  I am really troubled by this Story and Enterta...   \n",
      "2        5701   3667  A near-perfect film version of a downright glo...   \n",
      "3       47191  40892  Keep your expectations low.  Really really low...   \n",
      "4       40957  15367  \"they dont make em like this no more...\"well.....   \n",
      "\n",
      "   overall  votes_up  votes_all  label  \n",
      "0      5.0         6          7      0  \n",
      "1      3.0        99        134      0  \n",
      "2      4.0        14         14      1  \n",
      "3      1.0         4          7      0  \n",
      "4      5.0         3          6      0  \n",
      "测试集前五行：\n",
      "   Id  reviewerID   asin                                         reviewText  \\\n",
      "0   0       82947  37386  I REALLY wanted this series but I am in SHOCK ...   \n",
      "1   1       10154  23543  I have to say that this is a work of art for m...   \n",
      "2   2        5789   5724  Alien 3 is certainly the most controversal fil...   \n",
      "3   3        9198   5909  I love this film...preachy?  Well, of course i...   \n",
      "4   4       33252  21214  Even though I previously bought the Gamera Dou...   \n",
      "\n",
      "   overall  \n",
      "0      1.0  \n",
      "1      4.0  \n",
      "2      3.0  \n",
      "3      5.0  \n",
      "4      5.0  \n"
     ]
    }
   ],
   "source": [
    "# 读取训练集和测试集\n",
    "train_df = pd.read_csv(DATA_DIR / \"train.csv\", sep='\\t')\n",
    "test_df = pd.read_csv(DATA_DIR / \"test.csv\", sep='\\t')\n",
    "\n",
    "# 查看数据集的大小和前几行\n",
    "print(f\"训练集大小：{len(train_df)}\")\n",
    "print(f\"测试集大小：{len(test_df)}\")\n",
    "print(\"训练集前五行：\")\n",
    "print(train_df.head())\n",
    "print(\"测试集前五行：\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 文本特征的处理，使用了TF-IDF（Term Frequency-Inverse Document Frequency）向量化方法。\n",
    "\n",
    "TF-IDF 向量化：\n",
    "\n",
    "TfidfVectorizer 是 scikit-learn 库中用于将文本转换为 TF-IDF 表示的工具。\n",
    "stop_words='english' 意味着在向量化的过程中将会去除英语停用词，这些是在文本中常见但通常没有实际意义的单词。\n",
    "word_model.fit_transform(train_df['reviewText']) 用于拟合并转换训练集的 'reviewText' 列，得到 TF-IDF 表示的训练集文本特征 train_X。\n",
    "word_model.transform(test_df['reviewText']) 用于将测试集的 'reviewText' 列转换为 TF-IDF 表示，得到测试集文本特征 test_X。\n",
    "拼接总评分特征：\n",
    "\n",
    "将每个文本的总评分（'overall' 列）通过 scipy.sparse.hstack 水平拼接到对应的 TF-IDF 特征矩阵中。\n",
    "这样，每个文本的 TF-IDF 特征矩阵将会包括其对应的总评分特征。总评分特征还被除以5，可能是为了归一化到0-1范围，因为总评分通常在1-5之间。\n",
    "最终，train_X 和 test_X 包含了处理好的文本特征，可以用于训练和测试机器学习模型。这个过程是常见的在文本分类任务中，结合文本信息和其他特征以提高模型性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf/idf 处理文本特征\n",
    "word_model = TfidfVectorizer(stop_words='english')\n",
    "train_X = word_model.fit_transform(train_df['reviewText'])\n",
    "test_X = word_model.transform(test_df['reviewText']) \n",
    "\n",
    "# 拼上总评分特征\n",
    "train_X = scipy.sparse.hstack([train_X, train_df['overall'].values.reshape((-1, 1)) / 5])\n",
    "test_X = scipy.sparse.hstack([test_X, test_df['overall'].values.reshape((-1, 1)) / 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ensemble 算法实现\n",
    "4.1这些函为了实现 bagging（自助采样集成）的一部分，其中通过构造多个分类器，每个分类器使用自助采样的样本进行训练，最后通过平均它们的预测概率来提高模型的鲁棒性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数，根据分类器名称构造分类器对象\n",
    "def construct_clf(clf_name):\n",
    "    clf = None\n",
    "    if clf_name == 'SVM':\n",
    "        clf = svm.LinearSVC()\n",
    "    elif clf_name == 'DTree':\n",
    "        clf = DecisionTreeClassifier(max_depth=10, class_weight='balanced')\n",
    "    elif clf_name == 'NB':\n",
    "        clf = BernoulliNB()\n",
    "    clf = CalibratedClassifierCV(clf, cv=2, method='sigmoid')  # 概率校正\n",
    "    return clf\n",
    "\n",
    "# 定义一个函数，获取自助采样\n",
    "def get_bootstrap_sample(X, Y):\n",
    "    sample_idx = np.random.choice(len(Y), len(Y), replace=True)\n",
    "    return X[sample_idx], Y[sample_idx]\n",
    "\n",
    "# 定义一个函数，计算平均预测概率\n",
    "def average_predictions(classifier, X, Y, num_iter, test_X):\n",
    "    predictions = [classifier.fit(*get_bootstrap_sample(X, Y)).predict_proba(test_X)[:, 1]\n",
    "                   for _ in range(num_iter)]\n",
    "    return np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2通过使用不同的自助采样训练数据，构造多个相似但略有不同的基本分类器，最后通过平均它们的预测结果来提高模型的性能和鲁棒性。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个类，实现Bagging算法\n",
    "class Bagging:\n",
    "    def __init__(self, clf, num_iter):\n",
    "        self.clf = clf\n",
    "        self.num_iter = num_iter\n",
    "        \n",
    "    def fit_predict(self, X, Y, test_X):\n",
    "        clf = clone(self.clf)\n",
    "        return average_predictions(clf, X, Y, self.num_iter, test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3这些函数的组合用于 AdaBoost 算法的每一轮迭代，其中每个基本分类器的权重和性能都根据前一轮的表现进行调整。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数，计算beta值\n",
    "def compute_beta(error):\n",
    "    return error / (1 - error)\n",
    "\n",
    "# 定义一个函数，更新权重\n",
    "def update_weights(weights, predictions, Y, beta):\n",
    "    weights *= np.where(predictions == Y, beta, 1)\n",
    "    return weights / weights.sum()\n",
    "\n",
    "# 定义一个函数，计算加权预测概率\n",
    "def weighted_predictions(classifier, X, Y, weights, test_X):\n",
    "    classifier.fit(X, Y, sample_weight=weights)\n",
    "    predictions = classifier.predict(X)\n",
    "    predict_proba = classifier.predict_proba(test_X)[:, 1]\n",
    "    return predictions, predict_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4通过构造一系列基本分类器，每个分类器的权重由前一轮的表现来调整，最终得到一个加权平均的预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个类，实现AdaBoostM1算法\n",
    "class AdaBoostM1:\n",
    "    def __init__(self, clf, num_iter):\n",
    "        self.clf = clf\n",
    "        self.num_iter = num_iter\n",
    "        \n",
    "    def fit_predict(self, X, Y, test_X):\n",
    "        num_samples = len(Y)\n",
    "        clf = clone(self.clf)\n",
    "        weights = np.ones(num_samples) / num_samples\n",
    "        result_list = []\n",
    "        beta_list = []\n",
    "\n",
    "        for _ in range(self.num_iter):\n",
    "            predictions, predict_proba = weighted_predictions(clf, X, Y, weights, test_X)\n",
    "            error = np.dot(weights, predictions != Y)\n",
    "            \n",
    "            if error > 0.5:\n",
    "                break\n",
    "\n",
    "            beta = compute_beta(error)\n",
    "            weights = update_weights(weights, predictions, Y, beta)\n",
    "            beta_list.append(beta)\n",
    "            result_list.append(predict_proba)\n",
    "\n",
    "        beta_list = np.log(1 / np.array(beta_list))\n",
    "        weights = beta_list / np.sum(beta_list)\n",
    "        \n",
    "        result = np.dot(weights, result_list)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 测试并生成结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机数种子\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# 构造分类器\n",
    "CLF_NAME = 'SVM' # 分类器名称，可以是'DTree', 'SVM', 'NB'\n",
    "clf = construct_clf(CLF_NAME)\n",
    "\n",
    "# 选择算法\n",
    "choose = Bagging(clf, NUM_ITER)\n",
    "#choose = AdaBoostM1(clf, NUM_ITER)\n",
    "\n",
    "# 训练并预测\n",
    "y_predict = choose.fit_predict(train_X.tocsr(), train_df['label'], test_X.tocsr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 生成提交结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()\n",
    "result_df['Id'] = test_df['Id'].values\n",
    "result_df['Predicted'] = y_predict\n",
    "result_df.to_csv(\"D:\\RESULT.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
